{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90ca59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms as T\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82beca-cbb0-4901-a4a2-1345856b8e9a",
   "metadata": {},
   "source": [
    "We start by defining the epochs and classes for our training script. We have 10 total fruits we wish to identify in the images and will start by running the training for 15 epochs. After you are done with the initial training, feel free to change the number of epochs to see how it changes your loss function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ece17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21b0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ubuntu/notebooks/data/fruit_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8ab0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"/home/ubuntu/notebooks/my_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e52946a-6730-473e-aee0-b3be4f56137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 26 03:54:50 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   23C    P0              56W / 300W |    780MiB / 23028MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229ed0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f26dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitDataset(torch.utils.data.Dataset):\n",
    "    # This function is run once when instantiating the Dataset object\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # In the first portion of this code we are taking our single dataset folder \n",
    "        # and splitting it into three folders based on the file types.\n",
    "        # This is just a preprocessing step.\n",
    "        list_ = os.listdir(root)\n",
    "        for file_ in list_:\n",
    "            name, ext = os.path.splitext(file_)\n",
    "            ext = ext[1:]\n",
    "            if ext == '':\n",
    "                continue\n",
    "\n",
    "            if os.path.exists(root+ '/' + ext):\n",
    "                shutil.move(root+'/'+file_, root+'/'+ext+'/'+file_)\n",
    "\n",
    "            else:\n",
    "                os.makedirs(root+'/'+ext)\n",
    "                shutil.move(root+'/'+file_, root+'/'+ext+'/'+file_)\n",
    "\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"png\"))))\n",
    "        self.label = list(sorted(os.listdir(os.path.join(root, \"json\"))))\n",
    "        self.box = list(sorted(os.listdir(os.path.join(root, \"npy\"))))\n",
    "        # We have our three attributes with the img, label, and box data\n",
    "\n",
    "    # Loads and returns a sample from the dataset at the given index idx\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, \"png\", self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        label_path = os.path.join(self.root, \"json\", self.label[idx])\n",
    "\n",
    "        with open(os.path.join('root', label_path), \"r\") as json_data:\n",
    "            json_labels = json.load(json_data)\n",
    "        \n",
    "        box_path = os.path.join(self.root, \"npy\", self.box[idx])\n",
    "        dat = np.load(str(box_path))   \n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i in dat:\n",
    "            obj_val = i[0]\n",
    "            xmin = torch.as_tensor(np.min(i[1]), dtype=torch.float32)\n",
    "            xmax = torch.as_tensor(np.max(i[3]), dtype=torch.float32)\n",
    "            ymin = torch.as_tensor(np.min(i[2]), dtype=torch.float32)\n",
    "            ymax = torch.as_tensor(np.max(i[4]), dtype=torch.float32)\n",
    "            if (ymax > ymin) & (xmax > xmin):\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                area = (xmax - xmin) * (ymax - ymin)\n",
    "            labels += [json_labels.get(str(obj_val)).get('class')]\n",
    "\n",
    "        label_dict = {}\n",
    "\n",
    "        # Labels for the dataset\n",
    "        static_labels = {\n",
    "            'apple' : 0,\n",
    "            'avocado' : 1,\n",
    "            'kiwi' : 2,\n",
    "            'lime' : 3,\n",
    "            'lychee' : 4,\n",
    "            'pomegranate' : 5,\n",
    "            'onion' : 6,\n",
    "            'strawberry' : 7,\n",
    "            'lemon' : 8,\n",
    "            'orange' : 9\n",
    "        }\n",
    "\n",
    "        labels_out = []\n",
    "        # Transforming the input labels into a static label dictionary to use\n",
    "        for i in range(len(labels)):\n",
    "            label_dict[i] = labels[i]\n",
    "\n",
    "        for i in label_dict:\n",
    "            fruit = label_dict[i]\n",
    "            final_fruit_label = static_labels[fruit]\n",
    "            labels_out += [final_fruit_label]\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels_out, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx]) \n",
    "        target[\"area\"] = area\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img= self.transforms(img)\n",
    "        return img, target\n",
    "\n",
    "    # Finally we have a function for the number of samples in our dataset\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925e7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b8b5f-c0c2-4cc0-985b-c37b45b25aa1",
   "metadata": {},
   "source": [
    "Create a function to collate our samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11f4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b17f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes): \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea9f447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FruitDataset(data_dir, get_transform(train=True))\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "dataset, batch_size=16, shuffle=True, collate_fn= collate_fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d7436-f2eb-4d06-8cfc-63a8c210a094",
   "metadata": {},
   "source": [
    "Next, we create our model with the 10 classes we have of fruit and transfer it to the GPU for training. We use [PyTorch SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) (stochastic gradient descent) as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e08427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = create_model(num_classes)\n",
    "model.to(device)\n",
    "    \n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001)\n",
    "len_dataloader = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e828acb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1/7, Loss: 3.978541374206543\n",
      "Epoch: 1 Iteration: 2/7, Loss: 3.3974666595458984\n",
      "Epoch: 1 Iteration: 3/7, Loss: 3.380915641784668\n",
      "Epoch: 1 Iteration: 4/7, Loss: 2.351797103881836\n",
      "Epoch: 1 Iteration: 5/7, Loss: 1.9960970878601074\n",
      "Epoch: 1 Iteration: 6/7, Loss: 2.01206111907959\n",
      "Epoch: 1 Iteration: 7/7, Loss: 1.975547432899475\n",
      "Epoch: 2 Iteration: 1/7, Loss: 2.0979387760162354\n",
      "Epoch: 2 Iteration: 2/7, Loss: 2.014479398727417\n",
      "Epoch: 2 Iteration: 3/7, Loss: 1.9199408292770386\n",
      "Epoch: 2 Iteration: 4/7, Loss: 1.8923652172088623\n",
      "Epoch: 2 Iteration: 5/7, Loss: 1.768477439880371\n",
      "Epoch: 2 Iteration: 6/7, Loss: 1.9157696962356567\n",
      "Epoch: 2 Iteration: 7/7, Loss: 1.7139626741409302\n",
      "Epoch: 3 Iteration: 1/7, Loss: 1.8533666133880615\n",
      "Epoch: 3 Iteration: 2/7, Loss: 1.8163641691207886\n",
      "Epoch: 3 Iteration: 3/7, Loss: 2.0194742679595947\n",
      "Epoch: 3 Iteration: 4/7, Loss: 1.789918065071106\n",
      "Epoch: 3 Iteration: 5/7, Loss: 1.7051714658737183\n",
      "Epoch: 3 Iteration: 6/7, Loss: 1.7313717603683472\n",
      "Epoch: 3 Iteration: 7/7, Loss: 1.7108453512191772\n",
      "Epoch: 4 Iteration: 1/7, Loss: 1.6819581985473633\n",
      "Epoch: 4 Iteration: 2/7, Loss: 1.6720497608184814\n",
      "Epoch: 4 Iteration: 3/7, Loss: 1.6724532842636108\n",
      "Epoch: 4 Iteration: 4/7, Loss: 1.7054049968719482\n",
      "Epoch: 4 Iteration: 5/7, Loss: 1.7336480617523193\n",
      "Epoch: 4 Iteration: 6/7, Loss: 1.7353520393371582\n",
      "Epoch: 4 Iteration: 7/7, Loss: 1.5799286365509033\n",
      "Epoch: 5 Iteration: 1/7, Loss: 1.6105715036392212\n",
      "Epoch: 5 Iteration: 2/7, Loss: 1.565167784690857\n",
      "Epoch: 5 Iteration: 3/7, Loss: 1.652657389640808\n",
      "Epoch: 5 Iteration: 4/7, Loss: 1.6095902919769287\n",
      "Epoch: 5 Iteration: 5/7, Loss: 1.661851406097412\n",
      "Epoch: 5 Iteration: 6/7, Loss: 1.597194790840149\n",
      "Epoch: 5 Iteration: 7/7, Loss: 1.8459867238998413\n",
      "Epoch: 6 Iteration: 1/7, Loss: 1.608857274055481\n",
      "Epoch: 6 Iteration: 2/7, Loss: 1.5420633554458618\n",
      "Epoch: 6 Iteration: 3/7, Loss: 1.5532596111297607\n",
      "Epoch: 6 Iteration: 4/7, Loss: 1.6620415449142456\n",
      "Epoch: 6 Iteration: 5/7, Loss: 1.519101619720459\n",
      "Epoch: 6 Iteration: 6/7, Loss: 1.5172187089920044\n",
      "Epoch: 6 Iteration: 7/7, Loss: 1.5432367324829102\n",
      "Epoch: 7 Iteration: 1/7, Loss: 1.5564433336257935\n",
      "Epoch: 7 Iteration: 2/7, Loss: 1.4886856079101562\n",
      "Epoch: 7 Iteration: 3/7, Loss: 1.5000783205032349\n",
      "Epoch: 7 Iteration: 4/7, Loss: 1.5359842777252197\n",
      "Epoch: 7 Iteration: 5/7, Loss: 1.5024935007095337\n",
      "Epoch: 7 Iteration: 6/7, Loss: 1.471661925315857\n",
      "Epoch: 7 Iteration: 7/7, Loss: 1.470583200454712\n",
      "Epoch: 8 Iteration: 1/7, Loss: 1.4200385808944702\n",
      "Epoch: 8 Iteration: 2/7, Loss: 1.554648518562317\n",
      "Epoch: 8 Iteration: 3/7, Loss: 1.469952940940857\n",
      "Epoch: 8 Iteration: 4/7, Loss: 1.4578807353973389\n",
      "Epoch: 8 Iteration: 5/7, Loss: 1.493703842163086\n",
      "Epoch: 8 Iteration: 6/7, Loss: 1.39007568359375\n",
      "Epoch: 8 Iteration: 7/7, Loss: 1.3867473602294922\n",
      "Epoch: 9 Iteration: 1/7, Loss: 1.4051353931427002\n",
      "Epoch: 9 Iteration: 2/7, Loss: 1.496881127357483\n",
      "Epoch: 9 Iteration: 3/7, Loss: 1.3759874105453491\n",
      "Epoch: 9 Iteration: 4/7, Loss: 1.3823540210723877\n",
      "Epoch: 9 Iteration: 5/7, Loss: 1.3783574104309082\n",
      "Epoch: 9 Iteration: 6/7, Loss: 1.4436180591583252\n",
      "Epoch: 9 Iteration: 7/7, Loss: 1.3635857105255127\n",
      "Epoch: 10 Iteration: 1/7, Loss: 1.3619292974472046\n",
      "Epoch: 10 Iteration: 2/7, Loss: 1.3732573986053467\n",
      "Epoch: 10 Iteration: 3/7, Loss: 1.4126322269439697\n",
      "Epoch: 10 Iteration: 4/7, Loss: 1.323428750038147\n",
      "Epoch: 10 Iteration: 5/7, Loss: 1.3724215030670166\n",
      "Epoch: 10 Iteration: 6/7, Loss: 1.3052690029144287\n",
      "Epoch: 10 Iteration: 7/7, Loss: 1.294320821762085\n",
      "Epoch: 11 Iteration: 1/7, Loss: 1.4030120372772217\n",
      "Epoch: 11 Iteration: 2/7, Loss: 1.2786750793457031\n",
      "Epoch: 11 Iteration: 3/7, Loss: 1.27528977394104\n",
      "Epoch: 11 Iteration: 4/7, Loss: 1.2956993579864502\n",
      "Epoch: 11 Iteration: 5/7, Loss: 1.30255126953125\n",
      "Epoch: 11 Iteration: 6/7, Loss: 1.263466477394104\n",
      "Epoch: 11 Iteration: 7/7, Loss: 1.3023343086242676\n",
      "Epoch: 12 Iteration: 1/7, Loss: 1.2693779468536377\n",
      "Epoch: 12 Iteration: 2/7, Loss: 1.2520400285720825\n",
      "Epoch: 12 Iteration: 3/7, Loss: 1.2729151248931885\n",
      "Epoch: 12 Iteration: 4/7, Loss: 1.2621620893478394\n",
      "Epoch: 12 Iteration: 5/7, Loss: 1.1720167398452759\n",
      "Epoch: 12 Iteration: 6/7, Loss: 1.2388920783996582\n",
      "Epoch: 12 Iteration: 7/7, Loss: 1.1499027013778687\n",
      "Epoch: 13 Iteration: 1/7, Loss: 1.2141592502593994\n",
      "Epoch: 13 Iteration: 2/7, Loss: 1.1874191761016846\n",
      "Epoch: 13 Iteration: 3/7, Loss: 1.1769850254058838\n",
      "Epoch: 13 Iteration: 4/7, Loss: 1.1609432697296143\n",
      "Epoch: 13 Iteration: 5/7, Loss: 1.142163634300232\n",
      "Epoch: 13 Iteration: 6/7, Loss: 1.1849353313446045\n",
      "Epoch: 13 Iteration: 7/7, Loss: 1.251213550567627\n",
      "Epoch: 14 Iteration: 1/7, Loss: 1.1030784845352173\n",
      "Epoch: 14 Iteration: 2/7, Loss: 1.110421061515808\n",
      "Epoch: 14 Iteration: 3/7, Loss: 1.0915772914886475\n",
      "Epoch: 14 Iteration: 4/7, Loss: 1.0969182252883911\n",
      "Epoch: 14 Iteration: 5/7, Loss: 1.235687017440796\n",
      "Epoch: 14 Iteration: 6/7, Loss: 1.0755990743637085\n",
      "Epoch: 14 Iteration: 7/7, Loss: 1.2237167358398438\n",
      "Epoch: 15 Iteration: 1/7, Loss: 1.0823363065719604\n",
      "Epoch: 15 Iteration: 2/7, Loss: 1.0650591850280762\n",
      "Epoch: 15 Iteration: 3/7, Loss: 1.0392372608184814\n",
      "Epoch: 15 Iteration: 4/7, Loss: 1.116995930671692\n",
      "Epoch: 15 Iteration: 5/7, Loss: 1.061025857925415\n",
      "Epoch: 15 Iteration: 6/7, Loss: 1.0840396881103516\n",
      "Epoch: 15 Iteration: 7/7, Loss: 0.9245966672897339\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ep = 0\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    ep += 1\n",
    "    i = 0    \n",
    "    for imgs, annotations in data_loader:\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {ep} Iteration: {i}/{len_dataloader}, Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a1e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379a5c4-c945-43f8-ad4c-7fcb3436bf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
